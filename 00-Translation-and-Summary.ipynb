{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "## Translation and Summary of Foreign News\n",
    "\n",
    "The goal of this project will be to get a summary of news in foreign countries by automatically scraping a newspapers headlines or articles, and then translating the text with OpenAI and also providing a summary format.\n",
    "\n",
    "### Data (Web Scraping)\n",
    "\n",
    "Let's explore how we could set-up a scraping job (note this has its limits, not every website can be easily scraped, your results may vary on other newpaper sites)."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "source": [
    "import requests\n",
    "import bs4"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "source": [
    "# This is just a limited example dictionary\n",
    "# As each website is different, this gets harder with more countries!\n",
    "country_newspapers = {\"Spain\":'https://elpais.com/', \n",
    "                       \"France\":\"https://www.lemonde.fr/\"\n",
    "                     }"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "source": [
    "# Note how \n",
    "country = input(\"What country are you interested in for a news summary? \")"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "What country are you interested in for a news summary? France\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "source": [
    "url = country_newspapers[country]"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "source": [
    "url"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "'https://www.lemonde.fr/'"
      ]
     },
     "metadata": {},
     "execution_count": 7
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "source": [
    "result = requests.get(url)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Parsing HTML "
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "source": [
    "soup = bs4.BeautifulSoup(result.text,\"lxml\")"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "source": [
    "# France Le Monde\n",
    "soup.select('.article__title-label')"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "[<p class=\"article__title-label\">Dans la bataille de l’accès aux soins, le gouvernement face à la colère des médecins</p>,\n",
       " <span class=\"article__title-label\">Pourquoi les prix de l’électricité s’envolent (et ne devraient pas redescendre)</span>,\n",
       " <span class=\"article__title-label\">Les pompes à chaleur sont-elles le futur du chauffage ?</span>,\n",
       " <span class=\"article__title-label\">« Moi, général de Gaulle » : l’appel du 18-Juin peut-il être reconstitué ?</span>,\n",
       " <span class=\"article__title-label\">Les images des séismes qui ont tué des milliers de personnes en Syrie et en Turquie</span>]"
      ]
     },
     "metadata": {},
     "execution_count": 13
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Clearly, this won't be the same title tag for Spain's El Pais, let's quickly test that out, then we can recombine these tags into the dictionary to simplify and have all the information in one location."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "source": [
    "spain_results = requests.get('https://elpais.com/')\n",
    "soup = bs4.BeautifulSoup(spain_results.text,\"lxml\")"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "source": [
    "len(soup.select('.c_t'))"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "123"
      ]
     },
     "metadata": {},
     "execution_count": 30
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "source": [
    "soup.select('.c_t')[:3]"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "[<h2 class=\"c_t\"><a href=\"/internacional/2023-02-13/haiti-se-deshace.html\">Haití se deshace</a></h2>,\n",
       " <h2 class=\"c_t c_t-sm\"><a href=\"/internacional/2023-02-13/los-presos-politicos-buscan-una-casa-de-acogida-en-el-destierro-en-estados-unidos.html\"><span class=\"c_t_i c_t_i-s _pr\" name=\"elpais_ico\"></span>Los presos políticos buscan una casa de acogida en el destierro en EE UU</a></h2>,\n",
       " <h2 class=\"c_t\"><a href=\"/america-colombia/2023-02-13/el-gobierno-de-colombia-y-el-eln-buscan-en-mexico-un-cese-al-fuego-permanente-que-haga-despegar-el-proceso-de-paz.html\">El Gobierno de Colombia y el ELN buscan en México un cese al fuego permanente que haga despegar el proceso de paz</a></h2>]"
      ]
     },
     "metadata": {},
     "execution_count": 32
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Grabbing Text\n",
    "\n",
    "Now we just need to figure out how to grab these headlines text:"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "source": [
    "for tag in soup.select('.c_t')[:3]:\n",
    "    print(tag.getText())"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Haití se deshace\n",
      "Los presos políticos buscan una casa de acogida en el destierro en EE UU\n",
      "El Gobierno de Colombia y el ELN buscan en México un cese al fuego permanente que haga despegar el proceso de paz\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Combining Dictionary Tag Title and URL"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "source": [
    "# \"Country\" : (URL,HTML_TAG)\n",
    "country_newspapers = {\"Spain\":('https://elpais.com/','.c_t'), \n",
    "                       \"France\":(\"https://www.lemonde.fr/\",'.article__title-label')\n",
    "                     }"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Translation via OpenAI"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "source": [
    "def create_prompt():\n",
    "    # Get Country\n",
    "    country = input(\"What country would you like a news summary for? \")\n",
    "    # Get country's URL newspaper and the HTML Tag for titles\n",
    "    try:\n",
    "        url,tag = country_newspapers[country]\n",
    "    except:\n",
    "        print(\"Sorry that country is not supported!\")\n",
    "        return\n",
    "    \n",
    "    # Scrape the Website\n",
    "    results = requests.get(url)\n",
    "    soup = bs4.BeautifulSoup(results.text,\"lxml\")\n",
    "    \n",
    "    # Grab all the text\n",
    "    country_headlines = ''\n",
    "    for item in soup.select(tag)[:3]:\n",
    "        country_headlines += item.getText()+'\\n'\n",
    "        \n",
    "    prompt = \"Detect the language of the news headlines below, then translate a summary of the headlines to English in a conversational tone:\\n\"\n",
    "    return prompt + country_headlines"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "source": [
    "prompt = create_prompt()"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "What country would you like a news summary for? Spain\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "source": [
    "print(prompt)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Detect the language of the news headlines below, then translate a summary of the headlines to English in a conversational tone:\n",
      "Haití se deshace\n",
      "Los presos políticos buscan una casa de acogida en el destierro en EE UU\n",
      "El Gobierno de Colombia y el ELN buscan en México un cese al fuego permanente que haga despegar el proceso de paz\n",
      "\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "source": [
    "import os\n",
    "import openai\n",
    "\n",
    "openai.api_key = os.getenv(\"OPENAI_API_KEY\")"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "source": [
    "response = openai.Completion.create(\n",
    "  model=\"text-davinci-003\",\n",
    "  prompt=prompt,\n",
    "  temperature=0.1, # Helps conversational tone a bit, optional\n",
    "  max_tokens=200,\n",
    "  top_p=1.0,\n",
    "  frequency_penalty=0.0,\n",
    "  presence_penalty=0.0\n",
    ")"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "source": [
    "print(response['choices'][0]['text'])"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "\n",
      "Language: Spanish\n",
      "\n",
      "The situation in Haiti is deteriorating. Political prisoners are seeking refuge in the United States. The Colombian government and the ELN are looking to Mexico for a permanent ceasefire that will help the peace process move forward.\n"
     ]
    }
   ],
   "metadata": {}
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}